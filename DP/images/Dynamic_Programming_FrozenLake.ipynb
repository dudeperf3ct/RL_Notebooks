{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "Dynamic_Programming_FrozenLake.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHLh_HzWfmZz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Dynamic Programming\n",
        "\n",
        "In this notebook, we will use DP to solve Frozen Lake Environment.\n",
        "\n",
        "Everything is explained in-detail in [blog post](https://dudeperf3ct.github.io/rl/2019/12/29/Tabular-Solution/#dynamic-programming). This is notebook which replicates the result of blog and runs in colab. Enjoy!\n",
        "\n",
        "#### Run in Colab\n",
        "\n",
        "You can run this notebook in google colab.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/dudeperf3ct/RL_Notebooks/blob/master/DP/Dynamic_Programming_FrozenLake.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb8AE51TMSYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import sys\n",
        "from gym.envs.toy_text.frozen_lake import FrozenLakeEnv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsODcHiXcpse",
        "colab_type": "text"
      },
      "source": [
        "### Frozen Lake Environment\n",
        "\n",
        "![frozen lake](images/frozen_lake.png)\n",
        "\n",
        "Winter is here. You and your friends were tossing around a frisbee at the park\n",
        "when you made a wild throw that left the frisbee out in the middle of the lake.\n",
        "\n",
        "The water is mostly frozen, but there are a few holes where the ice has melted.\n",
        "\n",
        "If you step into one of those holes, you'll fall into the freezing water.\n",
        "\n",
        "At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc.\n",
        "However, the ice is slippery, so you won't always move in the direction you intend.\n",
        "\n",
        "The surface is described using a grid like the following:\n",
        "\n",
        "![frozen](images/frozen.png)\n",
        "\n",
        "The episode ends when you reach the goal or fall in a hole.\n",
        "\n",
        "You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
        "\n",
        "An agent can take 4 actions when in any state \n",
        "\n",
        "* LEFT = 0\n",
        "* DOWN = 1\n",
        "* RIGHT = 2\n",
        "* UP = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6zQZEV2MSYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = FrozenLakeEnv()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnClreNObb5Y",
        "colab_type": "code",
        "outputId": "0d0dcaec-12e1-4934-e998-87bb8997b335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "env.render()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMHBwJnYksPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action = ['left', 'down', 'right', 'up']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gr_8DQocjrp",
        "colab_type": "code",
        "outputId": "63e0ef17-2831-4628-fcfc-a900e34ff5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 4x4 grid = 16 states\n",
        "print (\"Number of states:\", env.nS)\n",
        "# either go left, up, down or right\n",
        "print (\"Number of actions that an agent can take:\", env.nA)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of states: 16\n",
            "Number of actions that an agent can take: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqrjMTHhbg9",
        "colab_type": "code",
        "outputId": "52331f97-a249-49c8-bccb-4d3ba82afb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "# Where am I?\n",
        "print (\"Current state\", env.s)\n",
        "# What are my options?\n",
        "print (\"Transitions from current state:\", env.P[env.s])\n",
        "print (env.render())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current state 0\n",
            "Transitions from current state: {0: [(0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 4, 0.0, False)], 1: [(0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 4, 0.0, False), (0.3333333333333333, 1, 0.0, False)], 2: [(0.3333333333333333, 4, 0.0, False), (0.3333333333333333, 1, 0.0, False), (0.3333333333333333, 0, 0.0, False)], 3: [(0.3333333333333333, 1, 0.0, False), (0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 0, 0.0, False)]}\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wacYGnEcjuX",
        "colab_type": "code",
        "outputId": "135214fa-ddde-4246-fc7e-82ea17fc4cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Taking a step by selecting a random action from current state\n",
        "# next state: Where do I end up?\n",
        "# reward: What rewards did I recieve?\n",
        "# is_terminal: did I end up in the goal state?\n",
        "# t_prob: What is probability of ending up in next state taking that action?\n",
        "rnd_action = random.randint(0, 3)\n",
        "print (\"Action taken:\", action[rnd_action])\n",
        "next_state, reward, is_terminal, t_prob = env.step(rnd_action)\n",
        "print (\"Transition probability:\", t_prob)\n",
        "print (\"Next state:\", next_state)\n",
        "print (\"Reward recieved:\", reward)\n",
        "print (\"Terminal state:\", is_terminal)\n",
        "env.render()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action taken: right\n",
            "Transition probability: {'prob': 0.3333333333333333}\n",
            "Next state: 1\n",
            "Reward recieved: 0.0\n",
            "Terminal state: False\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOLZ9fOGiMl1",
        "colab_type": "text"
      },
      "source": [
        "### Policy Evaluation\n",
        "\n",
        "The goal in policy evaluation is to evaluate any given valid policy. Policy will be a matrix of shape (S, A) which provides mapping from states to action.\n",
        "\n",
        "$$\n",
        "\\begin{aligned} \n",
        "v_{k+1}(s) &= \\sum_{a \\in \\mathcal{A}}\\pi(a \\vert s)[\\mathcal{R}_{s}^{a} + \\gamma \\sum_{s^{'} \\in S}\\mathcal{P}_{ss^{'}}^{a}v{k}(s^{'})]\n",
        "\\end{aligned} \n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLbOQnVcMSYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def policy_eval(policy, env, discount_factor=1.0, theta=0.00001):\n",
        "    \"\"\"\n",
        "    Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
        "    \n",
        "    Args:\n",
        "        policy: [S, A] shaped matrix representing the policy.\n",
        "        env: env.P represents the transition probabilities of the environment.\n",
        "             env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
        "             env.nS is a number of states in the environment. \n",
        "             env.nA is a number of actions in the environment.\n",
        "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
        "        discount_factor: Gamma discount factor.\n",
        "    \n",
        "    Returns:\n",
        "        Vector of length env.nS representing the value function.\n",
        "    \"\"\"\n",
        "    # Start with a random (all 0) value function\n",
        "    V = np.zeros(env.nS)\n",
        "    values = list()\n",
        "    values.append(np.copy(V))\n",
        "    \n",
        "    while True:\n",
        "        delta = 0\n",
        "        # for each state s in the environment\n",
        "        for s in range(env.nS):\n",
        "            \n",
        "            # what actions can be taken when in state s according to policy\n",
        "            A = policy[s]\n",
        "            v_s = 0\n",
        "            \n",
        "            # for each action a that can be taken when in state s under policy with probability action_prob\n",
        "            for a, action_prob in enumerate(A):\n",
        "            \n",
        "               # expected returns from all states that can be visited taking action a\n",
        "               for (t_prob, next_state, reward, is_terminal) in env.P[s][a]:\n",
        "                   # probability of taking action a * probability of ending in next state *\n",
        "                   # [immediate reward + discount * returns from next state]\n",
        "                   v_s += action_prob * t_prob * (reward + discount_factor * V[next_state])\n",
        "            \n",
        "            delta = max(delta, abs(v_s-V[s]))\n",
        "            V[s] = v_s\n",
        "        \n",
        "        values.append(np.copy(V))\n",
        "        \n",
        "        # values of all states is less than theta\n",
        "        if (delta < theta):\n",
        "            break\n",
        "    return V, values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGBQjIf04IKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# equiprobable random policy\n",
        "random_policy = np.ones([env.nS, env.nA]) / env.nA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSEZYSbIMSY2",
        "colab_type": "code",
        "outputId": "0734a8e7-6137-4396-e655-2e084f41bf2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "v, val = policy_eval(random_policy, env)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.87 ms, sys: 24 µs, total: 7.89 ms\n",
            "Wall time: 7.43 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA2G9yfJ-qmm",
        "colab_type": "code",
        "outputId": "829f5d6b-9f97-4af4-8669-4698cd865acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(\"Value Function:\")\n",
        "print(v)\n",
        "print(\"\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value Function:\n",
            "[0.013911   0.01161424 0.02094062 0.01046758 0.01623478 0.\n",
            " 0.04074774 0.         0.03479961 0.08816698 0.14205099 0.\n",
            " 0.         0.17581855 0.4392897  0.        ]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wabzrONkBIEo",
        "colab_type": "code",
        "outputId": "b663d6f5-3bf2-4394-a8ba-4b7283111066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (len(val))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmPK69m4DeZg",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def show_anim(val, name='value_function', n=4):\n",
        "\n",
        "    def barlist(n):\n",
        "        return val[n]\n",
        "\n",
        "    fig=plt.figure()\n",
        "    x=range(16)\n",
        "    ylim = [-25, 0]\n",
        "    barcollection = plt.bar(x, barlist(0))\n",
        "    plt.ylim(ylim)\n",
        "\n",
        "    def animate(i):\n",
        "        y = barlist(i+1)\n",
        "        plt.cla()\n",
        "        bar = plt.gca().bar(x, barlist(i))\n",
        "        plt.ylim(ylim)\n",
        "\n",
        "    anim=animation.FuncAnimation(fig,animate, blit=False, repeat=False, frames=n)\n",
        "\n",
        "    anim.save(name+'.mp4', writer=animation.FFMpegWriter(fps=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKQm81dqE3hB",
        "colab_type": "code",
        "outputId": "484d35d6-1a1c-49fe-df57-9488abba5678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "show_anim(val, 'value_function', n=len(val)-1)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHreOkTX0_nz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "6543d5d3-b28e-412d-fa40-7c9698d82c42"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('value_function.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<video width=400 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T5jFhrmGdyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "36b3ffe6-e74d-4221-c845-4a56579e0104"
      },
      "source": [
        "print (\"Reshaped Value Function:\")\n",
        "print(np.reshape(v, (4, 4)))\n",
        "print(\"\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaped Value Function:\n",
            "[[0.013911   0.01161424 0.02094062 0.01046758]\n",
            " [0.01623478 0.         0.04074774 0.        ]\n",
            " [0.03479961 0.08816698 0.14205099 0.        ]\n",
            " [0.         0.17581855 0.4392897  0.        ]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYeK9HPuClQC",
        "colab_type": "text"
      },
      "source": [
        "### Policy Iteration\n",
        "\n",
        "The goal in policy iteration is to find optimal policy.\n",
        "\n",
        "Policy iteration consits of 2 steps. Given a policy, we evaluate given policy using policy evaluation from above and we act greedy with respect to value function obtained in policy evaluation step to get a improved policy. This step is called policy improvement step. We repeat these 2 steps until policy converges i.e there is no change in old and new improved policy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hndLL0YcCeMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def policy_eval(policy, env, discount_factor=1.0, theta=0.00001):\n",
        "    \"\"\"\n",
        "    Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
        "    \n",
        "    Args:\n",
        "        policy: [S, A] shaped matrix representing the policy.\n",
        "        env: env.P represents the transition probabilities of the environment.\n",
        "             env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
        "             env.nS is a number of states in the environment. \n",
        "             env.nA is a number of actions in the environment.\n",
        "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
        "        discount_factor: Gamma discount factor.\n",
        "    \n",
        "    Returns:\n",
        "        Vector of length env.nS representing the value function.\n",
        "    \"\"\"\n",
        "    # Start with a random (all 0) value function\n",
        "    V = np.zeros(env.nS)\n",
        "    values = list()\n",
        "    values.append(np.copy(V))\n",
        "    \n",
        "    while True:\n",
        "        delta = 0\n",
        "        # for each state s in the environment\n",
        "        for s in range(env.nS):        \n",
        "            # what actions can be taken when in state s according to policy\n",
        "            A = policy[s]\n",
        "            v_s = 0  \n",
        "            # for each action a that can be taken when in state s under policy with probability action_prob\n",
        "            for a, action_prob in enumerate(A):\n",
        "               # expected returns from all states that can be visited taking action a\n",
        "               for (t_prob, next_state, reward, is_terminal) in env.P[s][a]:\n",
        "                   # probability of taking action a * probability of ending in next state *\n",
        "                   # [immediate reward + discount * returns from next state]\n",
        "                   v_s += action_prob * t_prob * (reward + discount_factor * V[next_state])      \n",
        "            delta = max(delta, abs(v_s-V[s]))\n",
        "            V[s] = v_s     \n",
        "        values.append(np.copy(V))    \n",
        "        # values of all states is less than theta\n",
        "        if (delta < theta):\n",
        "            break\n",
        "    return V, values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOj62UaMCeKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def policy_improvement(env, policy_eval_fn=policy_eval, discount_factor=1.0):\n",
        "    \"\"\"\n",
        "    Policy Improvement Algorithm. Iteratively evaluates and improves a policy\n",
        "    until an optimal policy is found.\n",
        "    \n",
        "    Args:\n",
        "        env: The OpenAI envrionment.\n",
        "        policy_eval_fn: Policy Evaluation function that takes 3 arguments:\n",
        "            policy, env, discount_factor.\n",
        "        discount_factor: gamma discount factor.\n",
        "        \n",
        "    Returns:\n",
        "        A tuple (policy, V). \n",
        "        policy is the optimal policy, a matrix of shape [S, A] where each state s\n",
        "        contains a valid probability distribution over actions.\n",
        "        V is the value function for the optimal policy.\n",
        "        \n",
        "    \"\"\"\n",
        "    # Start with a equiprobable policy\n",
        "    policy = np.ones([env.nS, env.nA]) / env.nA\n",
        "    val = list()\n",
        "    pol = list()\n",
        "    while True:\n",
        "        # evaluate the given policy\n",
        "        V, _ = policy_eval_fn(policy, env, discount_factor)\n",
        "        val.append(np.copy(V))\n",
        "        # improve the policy by being greedy wrt to current value function\n",
        "        policy_stable = True\n",
        "        old_policy = policy.copy()\n",
        "        pol.append(np.copy(old_policy))\n",
        "        for s in range(env.nS):\n",
        "            v = []      \n",
        "            # find returns for each action a\n",
        "            for a in range(env.nA):   \n",
        "                # expected returns from all states that can be visited taking action a\n",
        "                v_s = 0\n",
        "                for (t_prob, next_state, reward, is_terminal) in env.P[s][a]:\n",
        "                    # probability of taking action a * probability of ending in next state *\n",
        "                    # [immediate reward + discount * returns from next state]\n",
        "                    v_s += t_prob * (reward + discount_factor * V[next_state])\n",
        "                v.append(v_s)\n",
        "            policy[s] = np.eye(env.nA)[np.argmax(v)]\n",
        "            if (np.argmax(v) != np.argmax(old_policy[s])):\n",
        "                policy_stable = False\n",
        "        # if policy no longer improves, we found optimal policy\n",
        "        if (policy_stable):\n",
        "            return (policy, V, val, pol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPhB_ONWC8z4",
        "colab_type": "code",
        "outputId": "695e8e2b-3b8c-458b-a769-ae3b12987fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "%%time\n",
        "policy, v, val, pol = policy_improvement(env)\n",
        "print(\"Policy Probability Distribution:\")\n",
        "print(policy)\n",
        "print(\"\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Policy Probability Distribution:\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "\n",
            "CPU times: user 106 ms, sys: 8.18 ms, total: 114 ms\n",
            "Wall time: 104 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lShEGgLCeHp",
        "colab_type": "code",
        "outputId": "faf2ed7c-e2f5-4864-b7e1-2402e505794b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "print(\"Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\")\n",
        "actions = np.stack([action for _ in range(len(policy))], axis=0)\n",
        "print (np.reshape(np.argmax(policy, axis=1), (4, 4)))\n",
        "print (\"\")\n",
        "\n",
        "print (\"Optimal Policy:\")\n",
        "print(np.take(actions, np.reshape(np.argmax(policy, axis=1), (4, 4))))\n",
        "print(\"\")\n",
        "\n",
        "print (\"Reshaped Optimal Value Function:\")\n",
        "print(np.reshape(v, (4, 4)))\n",
        "print(\"\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\n",
            "[[0 3 3 3]\n",
            " [0 0 0 0]\n",
            " [3 1 0 0]\n",
            " [0 2 1 0]]\n",
            "\n",
            "Optimal Policy:\n",
            "[['left' 'up' 'up' 'up']\n",
            " ['left' 'left' 'left' 'left']\n",
            " ['up' 'down' 'left' 'left']\n",
            " ['left' 'right' 'down' 'left']]\n",
            "\n",
            "Reshaped Optimal Value Function:\n",
            "[[0.8233628  0.82330813 0.82327014 0.82325081]\n",
            " [0.82337956 0.         0.52929815 0.        ]\n",
            " [0.8234058  0.82343946 0.76462706 0.        ]\n",
            " [0.         0.88229042 0.94114466 0.        ]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFITkQCoCgx4",
        "colab_type": "code",
        "outputId": "e80f947f-2224-4dc6-9cb0-8d72a248597f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (len(val), len(pol))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug-TC47lIU0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5a89356f-ffc0-4aaf-d31f-ed3b8201a028"
      },
      "source": [
        "val"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.013911  , 0.01161424, 0.02094062, 0.01046758, 0.01623478,\n",
              "        0.        , 0.04074774, 0.        , 0.03479961, 0.08816698,\n",
              "        0.14205099, 0.        , 0.        , 0.17581855, 0.4392897 ,\n",
              "        0.        ]),\n",
              " array([0.78026785, 0.65835646, 0.53645849, 0.53644635, 0.78029547,\n",
              "        0.        , 0.41456891, 0.        , 0.78033803, 0.78039135,\n",
              "        0.70725112, 0.        , 0.        , 0.85359075, 0.92679462,\n",
              "        0.        ]),\n",
              " array([0.8233628 , 0.82330813, 0.82327014, 0.82325081, 0.82337956,\n",
              "        0.        , 0.52929815, 0.        , 0.8234058 , 0.82343946,\n",
              "        0.76462706, 0.        , 0.        , 0.88229042, 0.94114466,\n",
              "        0.        ])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFkS82eOt7Ok",
        "colab_type": "code",
        "outputId": "636faa65-af42-45c7-8a98-71cf69347bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "show_anim(val, 'pi_value_function', n=len(val)-1)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uHG80OKF3EN",
        "colab_type": "code",
        "outputId": "dd33f063-713a-43b8-9279-a8e3b7b595e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('pi_value_function.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<video width=400 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ox6w8eKbt__7"
      },
      "source": [
        "### Generalized Policy Iteration (GPI)\n",
        "\n",
        "The goal in gpi is to find optimal policy and optimal value function.  \n",
        "\n",
        "In generalized policy iteration, we perform continuous iterations of each policy evaluation and policy iteration alternatively. The value function is altered to more closely approximate the value function for the current policy, and the policy is repeatedly improved with respect to the current value function. Eventually both approximate value function and policy converges to optimal value function and optimal policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jXT_Y48iuAAa",
        "colab": {}
      },
      "source": [
        "def policy_eval(policy, env, V, discount_factor=1.0, theta=0.00001):\n",
        "    \"\"\"\n",
        "    Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
        "    \n",
        "    Args:\n",
        "        policy: [S, A] shaped matrix representing the policy.\n",
        "        env: env.P represents the transition probabilities of the environment.\n",
        "             env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
        "             env.nS is a number of states in the environment. \n",
        "             env.nA is a number of actions in the environment.\n",
        "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
        "        discount_factor: Gamma discount factor.\n",
        "    \n",
        "    Returns:\n",
        "        Vector of length env.nS representing the value function.\n",
        "    \"\"\"\n",
        "    values = list()\n",
        "    values.append(np.copy(V))\n",
        "    \n",
        "    # for each state s in the environment\n",
        "    for s in range(env.nS):        \n",
        "        # what actions can be taken when in state s according to policy\n",
        "        A = policy[s]\n",
        "        v_s = 0  \n",
        "        # for each action a that can be taken when in state s under policy with probability action_prob\n",
        "        for a, action_prob in enumerate(A):\n",
        "            # expected returns from all states that can be visited taking action a\n",
        "            for (t_prob, next_state, reward, is_terminal) in env.P[s][a]:\n",
        "                # probability of taking action a * probability of ending in next state *\n",
        "                # [immediate reward + discount * returns from next state]\n",
        "                v_s += action_prob * t_prob * (reward + discount_factor * V[next_state])\n",
        "        V[s] = v_s     \n",
        "    values.append(np.copy(V))\n",
        "    return V, values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NV89zSjeuAAo",
        "colab": {}
      },
      "source": [
        "def policy_improvement(env, policy, V, discount_factor=1.0):\n",
        "    \"\"\"\n",
        "    Policy Improvement Algorithm. Iteratively evaluates and improves a policy\n",
        "    until an optimal policy is found.\n",
        "    \n",
        "    Args:\n",
        "        env: The OpenAI envrionment.\n",
        "        policy_eval_fn: Policy Evaluation function that takes 3 arguments:\n",
        "            policy, env, discount_factor.\n",
        "        discount_factor: gamma discount factor.\n",
        "        \n",
        "    Returns:\n",
        "        A tuple (policy, V). \n",
        "        policy is the optimal policy, a matrix of shape [S, A] where each state s\n",
        "        contains a valid probability distribution over actions.\n",
        "        V is the value function for the optimal policy.\n",
        "        \n",
        "    \"\"\"\n",
        "    # improve the policy by being greedy wrt to current value function\n",
        "    old_policy = policy.copy()\n",
        "    for s in range(env.nS):\n",
        "        v = []      \n",
        "        # find returns for each action a\n",
        "        for a in range(env.nA):   \n",
        "            # expected returns from all states that can be visited taking action a\n",
        "            v_s = 0\n",
        "            for (t_prob, next_state, reward, is_terminal) in env.P[s][a]:\n",
        "                # probability of taking action a * probability of ending in next state *\n",
        "                # [immediate reward + discount * returns from next state]\n",
        "                v_s += t_prob * (reward + discount_factor * V[next_state])\n",
        "            v.append(v_s)\n",
        "        policy[s] = np.eye(env.nA)[np.argmax(v)]\n",
        "    return policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGsz6XiN3Lew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gpi(env, policy, V, policy_eval_fn=policy_eval, policy_improve_fn=policy_improvement, discount_factor=1.0, theta=0.00001):\n",
        "    \n",
        "    count = 0\n",
        "    val = list()\n",
        "    pol = list()\n",
        "    while True:\n",
        "        V, _ = policy_eval_fn(policy, env, V, discount_factor, theta)\n",
        "        val.append(np.copy(V))\n",
        "        old_policy = policy.copy()\n",
        "        pol.append(np.copy(old_policy))\n",
        "        policy = policy_improve_fn(env, policy, V, discount_factor)\n",
        "        count += 1\n",
        "        if (np.array_equal(old_policy, policy)):\n",
        "            break\n",
        "\n",
        "    print (\"Number of iterations for optimal policy to converge:\", count)\n",
        "\n",
        "    return policy, V, val, pol"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "89c9f300-427f-4976-b413-cec4e6815f3c",
        "id": "EwjvTOZUuAA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "%%time\n",
        "# Start with a equiprobable policy\n",
        "policy = np.ones([env.nS, env.nA]) / env.nA\n",
        "\n",
        "# Start with a random (all 0) value function\n",
        "V = np.zeros(env.nS)\n",
        "\n",
        "policy, v, val, pol = gpi(env, policy, V)\n",
        "print(\"Policy Probability Distribution:\")\n",
        "print(policy)\n",
        "print(\"\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of iterations for optimal policy to converge: 8\n",
            "Policy Probability Distribution:\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "\n",
            "CPU times: user 6.82 ms, sys: 21 µs, total: 6.85 ms\n",
            "Wall time: 6.83 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a999feb-83d2-4952-be41-e8bc573bd57d",
        "id": "ymcnYB7guABA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "print(\"Reshaped Grid Policy:\")\n",
        "actions = np.stack([action for _ in range(len(policy))], axis=0)\n",
        "print (np.reshape(np.argmax(policy, axis=1), (4, 4)))\n",
        "print (\"\")\n",
        "\n",
        "print (\"Optimal Policy:\")\n",
        "print(np.take(actions, np.reshape(np.argmax(policy, axis=1), (4, 4))))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Optimal Value Function:\")\n",
        "print(np.reshape(v, (4, 4)))\n",
        "print(\"\")"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaped Grid Policy:\n",
            "[[1 3 2 3]\n",
            " [0 0 0 0]\n",
            " [3 1 0 0]\n",
            " [0 2 1 0]]\n",
            "\n",
            "Optimal Policy:\n",
            "[['down' 'up' 'right' 'up']\n",
            " ['left' 'left' 'left' 'left']\n",
            " ['up' 'down' 'left' 'left']\n",
            " ['left' 'right' 'down' 'left']]\n",
            "\n",
            "Optimal Value Function:\n",
            "[[0.02296398 0.03375586 0.07433939 0.04682928]\n",
            " [0.06147013 0.         0.14893563 0.        ]\n",
            " [0.1594876  0.33348622 0.40083283 0.        ]\n",
            " [0.         0.50735547 0.74247737 0.        ]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9e9743fc-af14-4fdb-fd46-006122e6c62e",
        "id": "VlGymhFkIEno",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (len(val), len(pol))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVtz1XsbIR8j",
        "colab_type": "code",
        "outputId": "8a3439d6-1fb7-431b-e5f7-6cd409bfb9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "val"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.25, 0.  ]),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.08333333, 0.        , 0.        , 0.08333333, 0.44444444,\n",
              "        0.        ]),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.02777778, 0.        , 0.        , 0.05555556,\n",
              "        0.17592593, 0.        , 0.        , 0.17592593, 0.54012346,\n",
              "        0.        ]),\n",
              " array([0.        , 0.        , 0.00925926, 0.00308642, 0.        ,\n",
              "        0.        , 0.0617284 , 0.        , 0.01851852, 0.12345679,\n",
              "        0.24176955, 0.        , 0.        , 0.27983539, 0.60665295,\n",
              "        0.        ]),\n",
              " array([0.        , 0.00308642, 0.02469136, 0.01028807, 0.00617284,\n",
              "        0.        , 0.0888203 , 0.        , 0.0473251 , 0.18964335,\n",
              "        0.29503887, 0.        , 0.        , 0.35871056, 0.65512117,\n",
              "        0.        ]),\n",
              " array([0.00308642, 0.00925926, 0.04126658, 0.02061424, 0.01886145,\n",
              "        0.        , 0.11210181, 0.        , 0.08527663, 0.24634202,\n",
              "        0.337855  , 0.        , 0.        , 0.42005792, 0.69172636,\n",
              "        0.        ]),\n",
              " array([0.01040238, 0.0203094 , 0.05799421, 0.03307423, 0.03818016,\n",
              "        0.        , 0.13194974, 0.        , 0.12326627, 0.2937264 ,\n",
              "        0.3724675 , 0.        , 0.        , 0.46850356, 0.72007664,\n",
              "        0.        ]),\n",
              " array([0.02296398, 0.03375586, 0.07433939, 0.04682928, 0.06147013,\n",
              "        0.        , 0.14893563, 0.        , 0.1594876 , 0.33348622,\n",
              "        0.40083283, 0.        , 0.        , 0.50735547, 0.74247737,\n",
              "        0.        ])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f6ab09c4-2c62-4824-c35c-b7847aa60fd4",
        "id": "xmacid0HIEoU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "show_anim(val, 'gpi_value_function', n=len(val)-1)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bcebf9e8-e461-4308-96f0-e6f11c717060",
        "id": "Hw6pvhpzIEop",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('gpi_value_function.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<video width=400 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USNK9M4it3qL",
        "colab_type": "text"
      },
      "source": [
        "### Value Iteration\n",
        "\n",
        "The goal in value iteration is to find optimal value function.\n",
        "\n",
        "\n",
        "$$ \\begin{aligned} v_{k+1}(s) &= max_{a \\in \\mathcal{A}}[\\mathcal{R}{s}^{a} + \\gamma \\sum{s^{'} \\in S}\\mathcal{P}{ss^{'}}^{a}v{k}(s^{'})]\\ \\end{aligned} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdZx1voet5Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def value_iteration(env, theta=0.0001, discount_factor=1.0):\n",
        "    \"\"\"\n",
        "    Value Iteration Algorithm.\n",
        "    \n",
        "    Args:\n",
        "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
        "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
        "            env.nS is a number of states in the environment. \n",
        "            env.nA is a number of actions in the environment.\n",
        "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
        "        discount_factor: Gamma discount factor.\n",
        "        \n",
        "    Returns:\n",
        "        A tuple (policy, V) of the optimal policy and the optimal value function.        \n",
        "    \"\"\"\n",
        "    # Start with a random (all 0) value function\n",
        "    V = np.zeros(env.nS)\n",
        "    values = list()\n",
        "    values.append(np.copy(V))\n",
        "    \n",
        "    while True:\n",
        "        delta = 0\n",
        "        # for each state s in the environment\n",
        "        for s in range(env.nS):\n",
        "            v = []\n",
        "            # for each action a that can be taken when in state s\n",
        "            for a in range(env.nA):\n",
        "                # expected returns from all states that can be visited taking action a\n",
        "                v_s = 0\n",
        "                for (t_prob, next_state, reward, is_terminal) in env.P[s][a]:\n",
        "                    # probability of taking action a * probability of ending in next state *\n",
        "                    # [immediate reward + discount * returns from next state]\n",
        "                    v_s += t_prob * (reward + discount_factor * V[next_state])\n",
        "                v.append(v_s)\n",
        "            delta = max(delta, abs(np.max(v)-V[s]))\n",
        "            V[s] = np.max(v)\n",
        "        values.append(np.copy(V))    \n",
        "        # values of all states is less than theta\n",
        "        if (delta < theta):\n",
        "            break\n",
        "    \n",
        "        for s in range(env.nS):\n",
        "            v = []      \n",
        "            # find returns for each action a\n",
        "            for a in range(env.nA):   \n",
        "                # expected returns from all states that can be visited taking action a\n",
        "                v_s = 0\n",
        "                for (t_prob, next_state, reward, is_terminal) in env.P[s][a]:\n",
        "                    # probability of taking action a * probability of ending in next state *\n",
        "                    # [immediate reward + discount * returns from next state]\n",
        "                    v_s += t_prob * (reward + discount_factor * V[next_state])\n",
        "                v.append(v_s)\n",
        "            policy[s] = np.eye(env.nA)[np.argmax(v)]\n",
        "    \n",
        "    return policy, V, values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBkv37KhuWx5",
        "colab_type": "code",
        "outputId": "c27a7c57-020a-420f-c772-91e3a88e726b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "%%time\n",
        "policy, v, val = value_iteration(env)\n",
        "\n",
        "print(\"Policy Probability Distribution:\")\n",
        "print(policy)\n",
        "print(\"\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Policy Probability Distribution:\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "\n",
            "CPU times: user 121 ms, sys: 222 µs, total: 122 ms\n",
            "Wall time: 122 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUqm_ETEuWvE",
        "colab_type": "code",
        "outputId": "abaaba5b-0502-4bbf-ce64-be07a039807b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "print(\"Reshaped Grid Policy:\")\n",
        "actions = np.stack([action for _ in range(len(policy))], axis=0)\n",
        "print (np.reshape(np.argmax(policy, axis=1), (4, 4)))\n",
        "print (\"\")\n",
        "\n",
        "print (\"Optimal Policy:\")\n",
        "print(np.take(actions, np.reshape(np.argmax(policy, axis=1), (4, 4))))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Optimal Value Function:\")\n",
        "print(np.reshape(v, (4, 4)))\n",
        "print(\"\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaped Grid Policy:\n",
            "[[0 3 3 3]\n",
            " [0 0 0 0]\n",
            " [3 1 0 0]\n",
            " [0 2 1 0]]\n",
            "\n",
            "Optimal Policy:\n",
            "[['left' 'up' 'up' 'up']\n",
            " ['left' 'left' 'left' 'left']\n",
            " ['up' 'down' 'left' 'left']\n",
            " ['left' 'right' 'down' 'left']]\n",
            "\n",
            "Optimal Value Function:\n",
            "[[0.82182145 0.82126109 0.82087163 0.82067347]\n",
            " [0.82199325 0.         0.52824715 0.        ]\n",
            " [0.82226231 0.82260733 0.76389785 0.        ]\n",
            " [0.         0.88171208 0.94085038 0.        ]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "70e6cb4f-1966-4450-fc7b-351d9b3d5526",
        "id": "k6B4qTl3IbU_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (len(val))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0bce9cfa-a0d1-4a01-9b36-1b2b59f85104",
        "id": "BCN33w7YIbVp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "show_anim(val, 'vi_value_function', n=len(val)-1)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca8e95ef-be5e-47a9-80fc-82051d30810d",
        "id": "E5oSjqdrIbV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('vi_value_function.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<video width=400 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    }
  ]
}